# 分类



分类评估指标:

1. 精确度（Accuracy）：分类正确的样本数占总样本数的比例。
2. 灵敏度（Sensitivity/Recall）：真实正类中被正确预测为正类的样本数占总的真实正类样本数的比例。
3. 特异度（Specificity）：真实负类中被正确预测为负类的样本数占总的真实负类样本数的比例。
4. 精确率（Precision）: 被预测为正类的样本中真正是正类的样本数占被预测为正类的样本数的比例。
5. F1值（F1-score）：综合考虑精确率和灵敏度，是精确率和灵敏度的调和平均数。
6. AUC值（Area Under the ROC Curve）：ROC曲线下方的面积，用于表示分类器的整体性能。
7. 对数损失（Logarithmic Loss）：评估分类结果的概率分布与真实结果的匹配程度。对数损失越小，模型的分类效果越好。

当对一个分类模型进行评估时，通常需要使用多个评估指标来综合考虑其性能。

### 精确度（Accuracy）

精确度是指分类正确的样本数占总样本数的比例，是最简单直接的评估指标。

精确度计算公式如下：	

$$ Accuracy = \frac{TP + TN}{TP + FP + TN + FN} $$

其中，$TP$ 表示真正类（True Positive）的样本数，即被分类器正确预测为正类的样本数；$TN$ 表示真负类（True Negative）的样本数，即被分类器正确预测为负类的样本数；$FP$ 表示误报样本（False Positive）的样本数，即被分类器错误地预测为正类的样本数；$FN$ 表示漏报样本（False Negative）的样本数，即被分类器错误地预测为负类的样本数。

### 灵敏度（Sensitivity/Recall）

灵敏度也称召回率，是指真实正类中被正确预测为正类的样本数占总的真实正类样本数的比例。灵敏度能够反映出分类器对于正样本的识别能力。

灵敏度计算公式如下：

$$ Sensitivity = \frac{TP}{TP + FN} $$

### 特异度（Specificity）

特异度是指真实负类中被正确预测为负类的样本数占总的真实负类样本数的比例。特异度能够反映出分类器对于负样本的识别能力。

特异度计算公式如下：

$$ Specificity = \frac{TN}{FP + TN} $$

### 精确率（Precision）

精确率是指被预测为正类的样本中真正是正类的样本数占被预测为正类的样本数的比例，能够反映出分类器对于正样本的预测准确性。

精确率计算公式如下：

$$ Precision = \frac{TP}{TP + FP} $$

### F1值（F1-score）

F1值是综合考虑精确率和灵敏度的调和平均数，能够综合评价分类器的预测准确性和召回率。

F1值计算公式如下：

$$ F1 = 2 * \frac{Precision * Sensitivity}{Precision + Sensitivity} = \frac{2 * TP}{2 * TP + FP + FN} $$

### AUC值（Area Under the ROC Curve）

AUC（Area Under the Curve）是一种常用的评估分类模型性能的指标，通常用于ROC曲线（Receiver Operating Characteristic curve）分析。AUC表示ROC曲线下方的面积，其取值范围在0到1之间。

以下是对AUC指标的详细解释：

**1. ROC曲线：**
- ROC曲线是以二分类模型为基础绘制出来的一条图形。
- 它展示了当分类器阈值变化时，真阳率（True Positive Rate, TPR）与假阳率（False Positive Rate, FPR）之间的关系。
- TPR表示正确预测为正例样本占所有实际正例样本比例；FPR表示错误预测为正例样本占所有实际负例样本比例。

**2. AUC计算：**
- AUC被定义为ROC曲线下方区域与坐标轴之间所围成的面积。
- 当一个完美预测器具有TPR=1且FPR=0时，其AUC等于1；而当一个随机猜测器无法进行准确预测时，其AUC约等于0.5。

**3. 解读和应用：**
- 较高的AUC意味着分类器具有较好的性能，在不同阈值设置下能够更准确地区分正负类别。
- AUC可以用于比较不同分类模型的性能，选择最佳模型。
- AUC还可以用来评估特征工程、调整阈值或优化算法等操作对模型性能的影响。

**4. 与准确率和召回率的区别：**
- 准确率（Accuracy）是一个全局指标，衡量分类器在所有样本上预测正确的比例。
- 召回率（Recall）是一个针对正例类别的指标，衡量分类器成功找到正例样本占所有实际正例样本比例。
- AUC更关注分类器在不同阈值下判定真假阳性的表现，因此它提供了一种更全面且相对鲁棒的评估方法。

总而言之，AUC是通过计算ROC曲线下方所围成面积来评估二分类模型性能的指标。它提供了一种直观且综合考虑TPR和FPR之间权衡关系的方式，并广泛应用于机器学习中各种分类问题中。

## 分类模型评估函数

`classification_report`和`confusion_matrix`是`scikit-learn（sklearn）`库中用于评估分类模型性能的两个非常有用的函数。

#### `classification_report`（分类报告）
`classification_report`函数用于生成分类模型的性能报告，该报告提供了模型在每个类别上的精确度（precision）、召回率（recall）、F1-score和支持度（support）等指标。

具体来说，`classification_report`函数的输入是真实的目标标签（y_true）和模型预测的标签（y_pred），它会根据这些标签计算并显示每个类别的以下指标：

- 精确度（Precision）：分类正确的正样本数量与所有被预测为正样本的数量的比值。表示模型预测为正样本的触发的真实正样本的概率。
- 召回率（Recall）：分类正确的正样本数量与所有真实正样本的数量的比值。表示模型能够正确找到的真实正样本的比例。
- F1-score：精确度和召回率的加权调和平均值，用于综合考虑两者的性能。F1-score的取值范围是0到1，值越高表示模型的性能越好。
- 支持度（Support）：每个类别在真实标签中的样本数量。

`classification_report`的输出类似于下面的示例：

```
              precision    recall  f1-score   support

    class 0       0.80      0.90      0.85        30
    class 1       0.75      0.60      0.67        20
    class 2       0.92      0.97      0.94        50

    accuracy                          0.86       100
   macro avg      0.82      0.82      0.82       100
weighted avg      0.85      0.86      0.85       100
```

在这个示例中，有三个类别（class 0、class 1和class 2），模型的平均精确度、召回率和F1-score等指标都会被报告。

#### `confusion_matrix`（混淆矩阵）
`confusion_matrix`函数用于创建分类模型的混淆矩阵。混淆矩阵是一种以矩阵形式显示模型分类结果的方法，它可以帮助我们了解模型在每个类别上的预测情况。

混淆矩阵的行表示真实标签，列表示预测标签。矩阵的每个元素表示模型将样本预测为某个类别的数量。通过观察混淆矩阵，我们可以分析模型在不同类别上的预测准确性、错误分类等情况。

以下是一个二分类问题的混淆矩阵示例：

```
[[85 15]
 [20 80]]
```

在这个示例中，真实标签包含两个类别，模型的预测结果将样本划分为四个区域：真正例（True Positive，TP）、真反例（True Negative，TN）、假正例（False Positive，FP）和假反例（False Negative，FN）。

- TP：模型将正样本正确地预测为正样本的数量。
- TN：模型将负样本正确地预测为负样本的数量。
- FP：模型将负样本错误地预测为正样本的数量。
- FN：模型将正样本错误地预测为负样本的数量。

混淆矩阵提供了对模型性能的更详细的了解，例如通过计算准确率（accuracy）、精确度、召回率和F1-score等指标。

# 回归

回归模型的评估指标有很多种，以下是其中常见的几种：

1. 均方误差（Mean Squared Error, MSE）：预测值与真实值之间的平均误差的平方和。
2. 均方根误差（Root Mean Squared Error, RMSE）：均方误差的平方根，它展示了实际数据与拟合数据之间的误差程度。
3. 平均绝对误差（Mean Absolute Error, MAE）：预测值与真实值之间的平均绝对误差。
4. R方系数（R-squared）：又称决定系数，用于说明自变量对因变量的解释程度，其取值范围为0-1之间。
5. 重要性分析（Feature Importance）：用于衡量特征在建立模型时的重要性。

不同的评估指标适用于不同的应用场景，需要根据具体情况选择合适的评估指标。



### 均方误差（Mean Squared Error, MSE）

均方误差是预测值与真实值之间的平均误差的平方和，它表示预测值与真实值之间的离散程度。

均方误差的公式如下：

$$ MSE = \frac{1}{n}\sum_{i=1}^{n}(y_i - \hat{y_i})^2 $$

其中 $y_i$ 是第 $i$ 个样本的真实值，$\hat{y_i}$ 是第 $i$ 个样本的预测值，$n$ 是样本数量。

###  均方根误差（Root Mean Squared Error, RMSE）

均方根误差是均方误差的平方根，它展示了实际数据与拟合数据之间的误差程度，并且与原始数据的单位相同。

均方根误差的公式如下：

$$ RMSE = \sqrt{\frac{1}{n}\sum_{i=1}^{n}(y_i - \hat{y_i})^2} $$

其中 $y_i$ 是第 $i$ 个样本的真实值，$\hat{y_i}$ 是第 $i$ 个样本的预测值，$n$ 是样本数量。

### 平均绝对误差（Mean Absolute Error, MAE）

平均绝对误差是预测值与真实值之间的平均绝对误差，它表示预测值与真实值之间的平均距离。

平均绝对误差的公式如下：

$$ MAE = \frac{1}{n}\sum_{i=1}^{n}|y_i - \hat{y_i}| $$

其中 $y_i$ 是第 $i$ 个样本的真实值，$\hat{y_i}$ 是第 $i$ 个样本的预测值，$n$ 是样本数量。

###  R方系数（R-squared）

R方系数也称决定系数，用于说明自变量对因变量的解释程度，其取值范围为0-1之间。当R方系数越接近1时，模型的拟合效果越好。

R方系数的公式如下：

$$ R^2 = 1 - \frac{\sum_{i=1}^{n}(y_i - \hat{y_i})^2}{\sum_{i=1}^{n}(y_i - \bar{y})^2} $$

其中 $y_i$ 是第 $i$ 个样本的真实值，$\hat{y_i}$ 是第 $i$ 个样本的预测值，$\bar{y}$ 是所有样本的平均值，$n$ 是样本数量。

### 重要性分析（Feature Importance）

在建立模型的过程中，特征的选择对模型的影响至关重要。因此，对特征的重要性进行分析可以帮助了解模型的建立过程。

特征的重要性可以通过不同的方法进行计算，如树模型中的信息增益、线性模型中的系数大小等。

总体来讲，以上这些指标都有各自的优缺点，在不同的场景下会有不同的选择。需要根据具体情况选择合适的评估指标。

