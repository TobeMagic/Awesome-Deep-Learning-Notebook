## SOTA 模型

SOTA模型是指当前领域内的最佳模型，全称为"State-of-the-Art"（即技术水平最先进的）模型。它代表了在某个特定任务或领域中目前取得的最好性能。

SOTA模型通常是通过比较不同研究论文、竞赛结果或实验数据来确定的。当一个新模型在特定任务上获得更高的准确度、更低的误差率或其他评价指标时，它将被认为超越了之前被广泛接受和使用的基准模型，并成为该任务领域内新的SOTA模型。

对于机器学习和深度学习领域而言，发展迅速且涌现出许多创新方法和架构。随着时间推移，新提出的算法往往会不断改善并超过以前最好的方法，从而成为新一代SOTA模型。

借助SOTA模型，在各种应用场景下可以获得更精确、有效或鲁棒等方面有所突破，并推动相关领域持续发展。因此，关注和理解当前状态下令人瞩目和优秀的SOTA模型对于跟踪科学进展以及设计自己项目中合适的模型非常重要。

## FLOP

FLOP是一个常用的度量单位，表示浮点运算（Floating Point Operations）的数量。它通常被用来衡量计算机或计算模型在执行某个任务时所需的计算量大小。

具体而言，FLOP指的是**一次浮点运算操作的数量**。这种操作可以是加法、减法、乘法或除法等基本数学运算，其中涉及到浮点数（即带有小数部分的数字）。例如，两个浮点数相乘就需要进行一次FLOP。

对于深度学习中使用的神经网络模型，在训练和推理过程中会涉及大量的矩阵乘法和卷积等复杂计算操作。因此，通过统计网络中总共执行了多少次FLOP可以评估其计算复杂性和效率。

实际上，在机器学习领域中经常使用更大规模单位TFLOPs（Tera-Floating Point Operations per Second）来描述每秒钟能够执行十亿亿次浮点运算。这可以作为衡量硬件设备如GPU或TPU速度和处理能力强弱的标准之一。

总结起来，FLOP是指代表浮点运算数量的度量单位，在机器学习领域用于评估任务所需的计算复杂性，并且常见地应用于衡量硬件设备的计算能力。

> 在TensorFlow 2中，可以使用tf.profiler 来估计模型的FLOP（浮点操作）数量。tf.profiler是一个用于分析和优化TensorFlow性能的工具。
>
> 下面是一种估计模型FLOP的常见方法：
>
> 1. 导入所需的库：
> ```python
> import tensorflow as tf
> from tensorflow.python.profiler import profiler_v2 as profiler
> ```
>
> 2. 构建你想要评估FLOP的模型，并编译它：
> ```python
> model = ... # 在此处构建你的模型
> 
> # 编译模型以准备进行推理
> model.compile(...)
> ```
>
> 3. **创建一个Profiler并运行推理过程**：
> ```python
> profiler.start()
> 
> # 运行你的数据通过模型进行推理，例如使用model.predict或者自定义训练循环等。
> ...
> 
> profiler.stop()
> ```
>
> 4. **生成报告并获取FLOP统计信息**：
> ```python
> profile_result = profiler.profile(
>     tf.get_default_graph(),
>     options=profiler.ProfileOptionBuilder.float_operation(), 
> )
> 
> flop_stats = profile_result.total_float_ops
> 
> print("Total FLOPs: ", flop_stats)
> ```
>
> 这将为您提供总共执行的浮点操作数（FLOPs）。请注意，这个数字表示了整个推理过程期间执行的所有浮点操作数量。
>
> 需要注意以下几点：
> - 在步骤3中，确保在运行前启动Profiler，并在完成后停止它。
> - 步骤4中会打印出总体FLOPs数量。
> - 请确保在安装了TensorFlow 2的环境中运行上述代码。
>
> 这是使用TensorFlow 2来估计模型FLOP的简单示例。通过分析模型的FLOP，您可以更好地了解和优化模型性能，并进行比较和选择不同架构或配置的模型。

## 饱和性质

饱和性质的激活函数是指在**输入数据较大或较小时，激活函数的导数趋近于0，导致梯度消失或爆炸**。这种情况下，神经网络可能会面临训练困难、收敛缓慢等问题。

常见的饱和性质的激活函数有Sigmoid函数和双曲正切（Tanh）函数。它们在输入接近极端值时，导数接近于0。对于Sigmoid函数而言，在输入非常大或非常小时，输出值会趋向于1或-1，并且导数几乎为0；对于Tanh函数而言，在输入非常大或非常小时，输出值也会趋向于1或-1，并且导数同样几乎为0。

相比之下，不饱和性质的激活函数没有上述问题并具有更好的表达能力。

## Benchmark & Baseline

在机器学习中，"benchmark"和"baseline"是两个常用的术语，它们在评估模型性能和比较算法效果方面有着不同的含义。

**Benchmark（基准）**通常指的是已经被广泛接受并**公认为具有`很高水平`或`最佳性能`的模型、算法或数据集**。这些基准可以作为参考标准，用来**衡量其他新提出的方法或模型是否具备更好的性能**。基准模型**通常是经过大规模实验验证，并且在特定领域内取得了优秀结果。**

例如，在图像分类任务中，**ImageNet数据集上训练得到的ResNet网络就成为了一个广泛使用且有效的基准模型**。当研究人员提出新的图像分类算法时，他们会**将其与ResNet进行比较以评估其相对性能。**

**Baseline（基线）**则表示**一种`简单但可行的解决方案或模型`作为初始点来进行比较**。它代表了问题领域内**`最简单、最容易实现`且效果尚可的方法**。通过建立一个基线，在之后**尝试改进和优化时可以更直观地看到所取得进展**。

设定一个合适而有意义的baseline非常重要，因为它可以帮助我们**衡量新方法的改进程度**。如果一个新模型或算法无法超过基线，那么很可能需要重新审视其有效性和可行性。

举个例子，在自然语言处理领域，建立一个简单的词袋模型可以作为baseline来评估更复杂的深度学习模型（如循环神经网络或注意力机制）在文本分类任务上的性能表现。

总结起来，benchmark是已经公认为**高水平或最佳性能**的参考标准（高手云集），用于比较和评估其他方法；而baseline则是问题领域内**最简单、可行但不必然优秀的解决方案，作为初始点进行对比和改进**（自我提升）。

## 多输出分类 & 多输出多分类

###多输出分类

多输出多分类问题在实际应用中非常常见。下面是一些具体的应用场景（**一个样本分为多个小类别**）：

1. 图像标注：给定一张图片，需要对其中的对象进行多个标签的分类，例如识别图像中的人、车辆和建筑等。

2. 自然语言处理（NLP）：在文本分类任务中，可能需要**同时预测文档的主题、情感倾向和情绪状态**等多个方面。

3. 音频分析：音频信号可以被**分为不同类别，比如音乐类型、说话者性别和语言等**。

4. 多模态任务：当涉及到结合不同类型数据时，如图像与文本或视频与声音之间，在每个模态上都有一个或多个输出变量来完成任务。

5. 医学影像诊断：医学领域中经常使用机器学习技术进行疾病诊断。在这种情况下，可能需要根据医学影像数据同时预测患者是否患有某种疾病以及该疾病所属的具体类型。

以上只是一些例子，并且实际应用场景非常广泛。对于这类问题，MLP等神经网络架构通常能够提供强大而灵活的建模能力，并且适合处理复杂关系和多个输出变量之间的相关性。

希望这些具体的应用场景能够帮助你理解多输出多分类问题在实际中的应用！

### 多输出多分类

多分类多输出问题在现实生活中有很多应用场景。以下是一些常见的例子(就是在大分类后的情况下再次通过多输出小分类）：

1. 图像识别：在图像识别任务中，我们可能需要将**输入图像分为多个类别，并同时预测每个类别的相关属性**。例如，在人脸识别中，我们可能需要将**人脸进行分类（男性/女性、年龄等），并预测额外的属性（眼镜、帽子等）**。

2. 自然语言处理：在自然语言处理任务中，我们经常面临着将文本分类到不同的类别，并根据需求生成相应的输出。例如，在情感分析中，我们可以使用模型对**文本进行情感分类（积极/消极），并进一步生成对特定方面或主题的评论。**

3. 多标签文本分类：某些情况下，一**个样本可能属于多个标签类别。比如新闻文章可以被归入多个主题（政治、体育、娱乐等）**。这种情况下就需要使用多标签分类算法来解决此问题。

4. 推荐系统：推荐系统通常会针对用户提供与其兴趣和偏好相关联的项目或商品。**这涉及到将项目划分到不同的类别，并根据用户历史数据进行个性化推荐。**

总之，当涉及到同时对多个输出进行分类或预测时，多分类多输出问题就变得非常有用。这种类型的问题可以帮助我们更好地理解和处理复杂的现实世界数据。

### 预训练

预训练是指在大规模未标注数据上进行的训练，目的是**学习到通用的特征表示**。与传统的监督学习不同，预训练使用的数据并没有标注好的标签，因此可以大量地获取数据来训练模型。

预训练常用的方法包括自编码器、对抗生成网络等。以自编码器为例，其基本思想是通过将**输入数据压缩成低维度编码，然后再将编码解压成输入数据的方式**，来学习到数据的特征表示。在预训练过程中，自编码器的目标是**最小化输入数据和解压缩后的重构数据之间的差异**，同时**保持编码维度足够小**，以避免过拟合。

由于预训练可以充分利用大规模未标注数据，因此得到的模型具有很好的泛化能力，并且可以被应用于各种不同的任务。例如，在自然语言处理领域，预训练模型如BERT、GPT等已经成为了该领域的主流技术，取得了很好的效果。

需要注意的是，预训练虽然可以充分利用未标注数据来学习特征，但是由于模型的结构相对复杂，预训练需要花费大量的计算资源和时间来完成。

> 在深度学习中，预训练和训练是两个不同的阶段。
>
> 预训练（pre-training）指的是在大规模未标注数据上进行的训练，目的是学习到通用的特征表示。预训练常用的方法包括自编码器、对抗生成网络等。预训练得到的模型通常称为预训练模型，这些模型通常具有很好的泛化能力，并且可以被应用于各种不同的任务。
>
> 训练（fine-tuning）则是指在**特定任务上对预训练模型进行微调**，使其适应该任务。训练通常需要**少量的标注数据**，并且通常使用反向传播算法进行优化，以最小化模型在该任务上的损失函数。通过训练，模型可以逐渐地适应特定任务的要求，并且在该任务上表现出色。
>
> 因此，预训练是一种通用模型的构建过程，而训练是针对具体任务的模型优化过程。

## 迁移学习

从 HDF5 加载预训练权重时，建议将权重加载到设置了检查点的原始模型中，然后将所需的权重/层提取到新模型中。

**示例：**

```python
def create_functional_model():
    inputs = keras.Input(shape=(784,), name="digits")
    x = keras.layers.Dense(64, activation="relu", name="dense_1")(inputs)
    x = keras.layers.Dense(64, activation="relu", name="dense_2")(x)
    outputs = keras.layers.Dense(10, name="predictions")(x)
    return keras.Model(inputs=inputs, outputs=outputs, name="3_layer_mlp")


functional_model = create_functional_model()
functional_model.save_weights("pretrained_weights.h5")

# In a separate program:
pretrained_model = create_functional_model()
pretrained_model.load_weights("pretrained_weights.h5")

# Create a new model by extracting layers from the original model:
extracted_layers = pretrained_model.layers[:-1]
extracted_layers.append(keras.layers.Dense(5, name="dense_3")) 
model = keras.Sequential(extracted_layers)
model.summary()
```
```
Model: "sequential_6"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 dense_1 (Dense)             (None, 64)                50240     
                                                                 
 dense_2 (Dense)             (None, 64)                4160      
                                                                 
 dense_3 (Dense)             (None, 5)                 325       
                                                                 
=================================================================
Total params: 54,725
Trainable params: 54,725
Non-trainable params: 0
_________________________________________________________________
```
